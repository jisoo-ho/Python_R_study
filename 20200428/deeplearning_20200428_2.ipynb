{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplearning_20200428_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgeb4QdbLPV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.tensorflow.org/tutorials/keras/text_classification?hl=ko\n",
        "# 이 예제는 이진 또는 클래스가 두개인 분류 문제입니다.\n",
        "# 이진 분류는 머신러닝에서 중요하고 널리 사용됩니다.\n",
        "\n",
        "# 여기에서는 인터넷 영화 데이터베이스에서 수집한 50,000개의 영화 리뷰 텍스트를 담은 IMDB 데이터셋을 사용하겠습니다.\n",
        "\n",
        "# 25,000개 리뷰는 훈련용으로, 25,000개는 테스트용으로 나뉘어져 있습니다.\n",
        "# 훈련 세트와 테스트 세트의 클래스는 균형이 잡혀 있습니다.\n",
        "# 즉, 긍정적인 리뷰와 부정적인 리뷰의 개수가 동일합니다.\n",
        "\n",
        "# tensorflow와 tf.keras 를 임포트 합니다.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# 헬퍼 라이브러리를 임포트합니다.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9OhJBfVMTaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IMDB 데이터셋 다운로드\n",
        "#IMDB 데이터셋은 텐서플로와 함께 제공됩니다. 리뷰(단어의 시퀀스(sequence))는 미리 \n",
        "#전처리해서 정수 시퀀스로 변환되어 있습니다. 각 정수는 [어휘 사전에 있는 특정 단어를 의미]합니다.\n",
        "#다음 코드는 IMDB 데이터셋을 컴퓨터에 다운로드합니다(또는 이전에 다운로드 받았다면 캐시된 복사본을 사용합니다):\n",
        "imdb = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
        "# 매개변수 num_words=10000은 훈련 데이터에서 가장 많이 등장하는 상위 10,000개의 단어를 선택합니다.\n",
        "# 데이터 크기를 적당하게 유지하기 위해 드물에 등장하는 단어는 제외하겠습니다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2tWFfpbMgY3",
        "colab_type": "code",
        "outputId": "de748689-3651-4876-d3f7-4eeb3ab2eb98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#데이터 탐색\n",
        "#잠시 데이터 형태를 알아 보죠. 이 데이터셋의 샘플은 전처리된 정수 배열입니다. \n",
        "#이 정수는 영화 리뷰에 나오는 단어를 나타냅니다. \n",
        "#레이블(label)은 정수 0 또는 1입니다. 0은 부정적인 리뷰이고 1은 긍정적인 리뷰입니다.\n",
        "print(\"훈련 샘플: {}, 레이블: {}\".format(len(train_data), len(train_labels)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 샘플: 25000, 레이블: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77nOI28DMr4v",
        "colab_type": "code",
        "outputId": "fdac5f15-61dd-40ef-963f-3b96fa06042d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#리뷰 텍스트는 어휘 사전의 특정 단어를 나타내는 정수로 변환되어 있습니다. 첫 번째 리뷰를 확인해 보죠:\n",
        "print(train_data[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIqixwjnNgUs",
        "colab_type": "code",
        "outputId": "5e93183a-9f0d-4329-aa71-954a3899d86d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 영화 리뷰들은 길이가 다릅니다. 다음 코드는 첫 번째 리뷰와 두 번째 리뷰에서 단어의 개수를 출력합니다.\n",
        "# 신경망의 입력은 길이가 같아야 하기 때문에 나중에 이 문제를 해결하겠습니다.\n",
        "len(train_data[0]), len(train_data[1])  # 텍스트 분류(단어의 수, 실제로 사용자가 리뷰한 데이터임. 0번과 1번의 길이가 다르다.)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyfiC3IgNlcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#정수를 단어로 다시 변환하기\n",
        "#정수를 다시 텍스트로 변환하는 방법이 있다면 유용할 것입니다. \n",
        "#여기에서는 정수와 문자열을 매핑한 딕셔너리(dictionary-사전) 객체에 질의하는 헬퍼(helper) 함수를 만들겠습니다:\n",
        "\n",
        "# 단어와 정수 인덱스를 매핑한 딕셔너리\n",
        "word_index = imdb.get_word_index() # 함수를 이용해 단어들에 대한 인덱스 번호 추출\n",
        "\n",
        "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} # .items : 키와 값 모두 꺼낸다.\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) # 키와 인덱스의 자리를 바꿔주는 작업\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhfPGctoNrz0",
        "colab_type": "code",
        "outputId": "39b26904-49e2-4e84-cb19-18d6cf4aa419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#이제 decode_review 함수를 사용해 첫 번째 리뷰 텍스트를 출력할 수 있습니다:\n",
        "decode_review(train_data[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rha3NZB_NuP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#데이터 준비\n",
        "'''\n",
        "리뷰-정수 배열-는 신경망에 주입하기 전에 텐서로 변환되어야 합니다. 변환하는 방법에는 몇 가지가 있습니다:\n",
        "\n",
        "원-핫 인코딩(one-hot encoding)은 정수 배열을 0과 1로 이루어진 벡터로 변환합니다.\n",
        " 예를 들어 배열 [3, 5]을 인덱스 3과 5만 1이고 나머지는 모두 0인 10,000차원 벡터로 변환할 수 있습니다. \n",
        " 그다음 실수 벡터 데이터를 다룰 수 있는 층-Dense 층-을 신경망의 첫 번째 층으로 사용합니다. \n",
        " 이 방법은 num_words * num_reviews 크기의 행렬이 필요하기 때문에 메모리를 많이 사용합니다.\n",
        "\n",
        "다른 방법으로는, 정수 배열의 길이가 모두 같도록 패딩(padding)을 추가해\n",
        " max_length * num_reviews 크기의 정수 텐서를 만듭니다.\n",
        " 이런 형태의 텐서를 다룰 수 있는 임베딩(embedding) 층을 신경망의 첫 번째 층으로 사용할 수 있습니다.\n",
        "\n",
        "이 튜토리얼에서는 두 번째 방식을 사용하겠습니다.\n",
        "\n",
        "영화 리뷰의 길이가 같아야 하므로 pad_sequences 함수를 사용해 길이를 맞추겠습니다\n",
        "'''\n",
        "\n",
        "#길이를 맞춰주는 함수(짧으면 뒤를 전부 0으로 채워준다.)\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256) # 최대 길이 값\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8tOtoU5N8W_",
        "colab_type": "code",
        "outputId": "117e7573-0db6-4113-eb81-a1d1f8ebd509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#샘플의 길이를 확인해 보죠:\n",
        "len(train_data[0]), len(train_data[1]) # 길이가 같아진 것을 확인할 수 있다."
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwzMDPRtN_av",
        "colab_type": "code",
        "outputId": "60235845-c6e9-4426-97a4-0efff4604b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "#(패딩된) 첫 번째 리뷰 내용을 확인해 보죠:\n",
        "print(train_data[0]) # 이 숫자는 해당 단어들을 정수화 시켜놓은 것 이다.\n",
        "# 끝 부분의 빈 공간들은 0으로 자동으로 채워진 것을 확인할 수 있다.(패딩시퀀스 함수로 인해 채워짐)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
            "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
            "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
            "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
            " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
            "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
            "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
            " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
            "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
            "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
            "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
            "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
            " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
            "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
            "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
            "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPc28TBiOAlO",
        "colab_type": "code",
        "outputId": "fecd00fc-1b0d-4e3b-d262-5a16848165d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "#모델 구성\n",
        "'''\n",
        "신경망은 층(layer)을 쌓아서 만듭니다. 이 구조에서는 두 가지를 결정해야 합니다:\n",
        "\n",
        "모델에서 얼마나 많은 층을 사용할 것인가?\n",
        "각 층에서 얼마나 많은 은닉 유닛(hidden unit)을 사용할 것인가?\n",
        "이 예제의 입력 데이터는 단어 인덱스의 배열입니다. \\\n",
        "예측할 레이블은 0 또는 1입니다. 이 문제에 맞는 모델을 구성해 보죠:\n",
        "'''\n",
        "# 입력 크기는 영화 리뷰 데이터셋에 적용된 어휘 사전의 크기입니다(10,000개의 단어)\n",
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential() #오전코드는 시퀀스안에 층을 만들었는데 이렇게 객체를 만들고 add하는것도 똑같음\n",
        "model.add(keras.layers.Embedding(vocab_size, 16, input_shape=(None,))) \n",
        "#Embedding층 : 갖고있는데이터는 정수, 정수로 만들어진데이터를 전달받게되면 아까 정수를 텍스트로 바꾼것처럼 입력받은 정수값을 인코딩된 정수값으로 내장시킨다는 뜻 \n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary() #만든 모델에 대한 요약"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rp3bip0OHDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "층을 순서대로 쌓아 분류기(classifier)를 만듭니다:\n",
        "\n",
        "첫 번째 층은 Embedding 층입니다. \n",
        "이 층은 정수로 인코딩된 단어를 입력 받고 각 단어 인덱스에 해당하는 임베딩 벡터를 찾습니다. \n",
        "이 벡터는 모델이 훈련되면서 학습됩니다. 이 벡터는 출력 배열에 새로운 차원으로 추가됩니다. \n",
        "최종 차원은 (batch, sequence, embedding)이 됩니다.\n",
        "\n",
        "그 다음 GlobalAveragePooling1D 층은 sequence 차원에 대해 평균을 계산하여 각 샘플에 대해 \n",
        "고정된 길이의 출력 벡터를 반환합니다. 이는 길이가 다른 입력을 다루는 가장 간단한 방법입니다.\n",
        "이 고정 길이의 출력 벡터는 16개의 은닉 유닛을 가진 완전 연결(fully-connected) 층(Dense)을 거칩니다.\n",
        "\n",
        "마지막 층은 하나의 출력 노드(node)를 가진 완전 연결 층입니다. \n",
        "sigmoid 활성화 함수를 사용하여 0과 1 사이의 실수를 출력합니다. \n",
        "이 값은 확률 또는 신뢰도를 나타냅니다.\n",
        "'''\n",
        "\n",
        "#은닉 유닛\n",
        "'''\n",
        "위 모델에는 입력과 출력 사이에 두 개의 중간 또는 \"은닉\" 층이 있습니다. \n",
        "출력(유닛 또는 노드, 뉴런)의 개수는 층이 가진 표현 공간(representational space)의 차원이 됩니다. \n",
        "다른 말로 하면, 내부 표현을 학습할 때 허용되는 네트워크 자유도의 양입니다.\n",
        "\n",
        "모델에 많은 은닉 유닛(고차원의 표현 공간)과 층이 있다면 네트워크는 더 복잡한 표현을 학습할 수 있습니다. \n",
        "하지만 네트워크의 계산 비용이 많이 들고 원치않는 패턴을 학습할 수도 있습니다. \n",
        "이런 표현은 훈련 데이터의 성능을 향상시키지만 테스트 데이터에서는 그렇지 못합니다. \n",
        "이를 과대적합(overfitting)이라고 부릅니다. 나중에 이에 대해 알아 보겠습니다.\n",
        "'''\n",
        "\n",
        "#손실 함수와 옵티마이저\n",
        "'''\n",
        "모델이 훈련하려면 손실 함수(loss function)과 옵티마이저(optimizer)가 필요합니다. \n",
        "이 예제는 이진 분류 문제이고 모델이 확률을 출력하므로(출력층의 유닛이 하나이고 sigmoid 활성화 함수를 사용합니다), \n",
        "binary_crossentropy 손실 함수를 사용하겠습니다.\n",
        "\n",
        "다른 손실 함수를 선택할 수 없는 것은 아닙니다. 예를 들어 mean_squared_error를 선택할 수 있습니다. \n",
        "하지만 일반적으로 binary_crossentropy가 확률을 다루는데 적합합니다. 이 함수는 확률 분포 간의 거리를 측정합니다. \n",
        "여기에서는 정답인 타깃 분포와 예측 분포 사이의 거리입니다.\n",
        "\n",
        "나중에 회귀(regression) 문제(예를 들어 주택 가격을 예측하는 문제)에 대해 살펴 볼 때 \n",
        "평균 제곱 오차(mean squared error) 손실 함수를 어떻게 사용하는지 알아 보겠습니다.\n",
        "\n",
        "이제 모델이 사용할 옵티마이저와 손실 함수를 설정해 보죠:\n",
        "'''\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMtszIPKOkA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#검증 세트 만들기\n",
        "'''\n",
        "모델을 훈련할 때 모델이 만난 적 없는 데이터에서 정확도를 확인하는 것이 좋습니다. \n",
        "원본 훈련 데이터에서 10,000개의 샘플을 떼어내어 검증 세트(validation set)를 만들겠습니다. \n",
        "(왜 테스트 세트를 사용하지 않을까요? 훈련 데이터만을 사용하여 모델을 개발하고 튜닝하는 것이 목표입니다. \n",
        "그 다음 테스트 세트를 사용해서 딱 한 번만 정확도를 평가합니다).\n",
        "'''\n",
        "x_val = train_data[:10000]\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3MAzd5ZOqOl",
        "colab_type": "code",
        "outputId": "cc4152b8-0273-41dd-8fb0-5ca78ed896a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#모델 훈련\n",
        "'''\n",
        "이 모델을 512개의 샘플로 이루어진 미니배치(mini-batch)에서 40번의 에포크(epoch) 동안 훈련합니다. \n",
        "x_train과 y_train 텐서에 있는 모든 샘플에 대해 40번 반복한다는 뜻입니다. \n",
        "훈련하는 동안 10,000개의 검증 세트에서 모델의 손실과 정확도를 모니터링합니다:\n",
        "'''\n",
        "history = model.fit(partial_x_train,# fit함수를 통해 훈련, history 변수를 만들어주었으니 history에 계속 누적되는 것임\n",
        "                    partial_y_train,\n",
        "                    epochs=40, # 40회 훈련\n",
        "                    batch_size=512, # 한번 훈련시킬 때 사용할 훈련데이터의 개수는 512개\n",
        "                    validation_data=(x_val, y_val), # 검증하는 코드\n",
        "                    verbose=1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.6919 - accuracy: 0.5321 - val_loss: 0.6903 - val_accuracy: 0.5051\n",
            "Epoch 2/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.6864 - accuracy: 0.6286 - val_loss: 0.6829 - val_accuracy: 0.6773\n",
            "Epoch 3/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.6750 - accuracy: 0.7208 - val_loss: 0.6685 - val_accuracy: 0.7392\n",
            "Epoch 4/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.6546 - accuracy: 0.7513 - val_loss: 0.6453 - val_accuracy: 0.7555\n",
            "Epoch 5/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.6249 - accuracy: 0.7747 - val_loss: 0.6140 - val_accuracy: 0.7840\n",
            "Epoch 6/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.5869 - accuracy: 0.8042 - val_loss: 0.5769 - val_accuracy: 0.7997\n",
            "Epoch 7/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.5430 - accuracy: 0.8217 - val_loss: 0.5346 - val_accuracy: 0.8158\n",
            "Epoch 8/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4946 - accuracy: 0.8439 - val_loss: 0.4922 - val_accuracy: 0.8282\n",
            "Epoch 9/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4495 - accuracy: 0.8543 - val_loss: 0.4541 - val_accuracy: 0.8404\n",
            "Epoch 10/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4094 - accuracy: 0.8691 - val_loss: 0.4216 - val_accuracy: 0.8487\n",
            "Epoch 11/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3757 - accuracy: 0.8782 - val_loss: 0.3952 - val_accuracy: 0.8562\n",
            "Epoch 12/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3463 - accuracy: 0.8873 - val_loss: 0.3734 - val_accuracy: 0.8617\n",
            "Epoch 13/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3211 - accuracy: 0.8927 - val_loss: 0.3564 - val_accuracy: 0.8659\n",
            "Epoch 14/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3005 - accuracy: 0.8993 - val_loss: 0.3432 - val_accuracy: 0.8688\n",
            "Epoch 15/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2821 - accuracy: 0.9034 - val_loss: 0.3321 - val_accuracy: 0.8716\n",
            "Epoch 16/40\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2669 - accuracy: 0.9087 - val_loss: 0.3224 - val_accuracy: 0.8736\n",
            "Epoch 17/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2535 - accuracy: 0.9140 - val_loss: 0.3142 - val_accuracy: 0.8797\n",
            "Epoch 18/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2403 - accuracy: 0.9180 - val_loss: 0.3078 - val_accuracy: 0.8806\n",
            "Epoch 19/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2294 - accuracy: 0.9219 - val_loss: 0.3028 - val_accuracy: 0.8812\n",
            "Epoch 20/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2188 - accuracy: 0.9246 - val_loss: 0.2989 - val_accuracy: 0.8835\n",
            "Epoch 21/40\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2081 - accuracy: 0.9289 - val_loss: 0.2951 - val_accuracy: 0.8835\n",
            "Epoch 22/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1991 - accuracy: 0.9322 - val_loss: 0.2925 - val_accuracy: 0.8841\n",
            "Epoch 23/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1895 - accuracy: 0.9369 - val_loss: 0.2902 - val_accuracy: 0.8842\n",
            "Epoch 24/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1813 - accuracy: 0.9407 - val_loss: 0.2885 - val_accuracy: 0.8841\n",
            "Epoch 25/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1739 - accuracy: 0.9439 - val_loss: 0.2879 - val_accuracy: 0.8845\n",
            "Epoch 26/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1674 - accuracy: 0.9470 - val_loss: 0.2865 - val_accuracy: 0.8850\n",
            "Epoch 27/40\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1617 - accuracy: 0.9494 - val_loss: 0.2868 - val_accuracy: 0.8853\n",
            "Epoch 28/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1561 - accuracy: 0.9515 - val_loss: 0.2862 - val_accuracy: 0.8854\n",
            "Epoch 29/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1492 - accuracy: 0.9545 - val_loss: 0.2869 - val_accuracy: 0.8863\n",
            "Epoch 30/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1427 - accuracy: 0.9569 - val_loss: 0.2877 - val_accuracy: 0.8865\n",
            "Epoch 31/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1382 - accuracy: 0.9588 - val_loss: 0.2889 - val_accuracy: 0.8860\n",
            "Epoch 32/40\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1324 - accuracy: 0.9612 - val_loss: 0.2906 - val_accuracy: 0.8854\n",
            "Epoch 33/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1268 - accuracy: 0.9626 - val_loss: 0.2912 - val_accuracy: 0.8851\n",
            "Epoch 34/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1234 - accuracy: 0.9651 - val_loss: 0.2933 - val_accuracy: 0.8861\n",
            "Epoch 35/40\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.1181 - accuracy: 0.9664 - val_loss: 0.2957 - val_accuracy: 0.8852\n",
            "Epoch 36/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1128 - accuracy: 0.9682 - val_loss: 0.2969 - val_accuracy: 0.8853\n",
            "Epoch 37/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1097 - accuracy: 0.9691 - val_loss: 0.2993 - val_accuracy: 0.8846\n",
            "Epoch 38/40\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1044 - accuracy: 0.9713 - val_loss: 0.3017 - val_accuracy: 0.8836\n",
            "Epoch 39/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1025 - accuracy: 0.9731 - val_loss: 0.3053 - val_accuracy: 0.8822\n",
            "Epoch 40/40\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.0982 - accuracy: 0.9740 - val_loss: 0.3072 - val_accuracy: 0.8839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcJWNUiUOwVu",
        "colab_type": "code",
        "outputId": "700a1935-0da7-464b-cd54-12196713ec7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#모델 평가\n",
        "#모델의 성능을 확인해 보죠. 두 개의 값이 반환됩니다. \n",
        "#손실(오차를 나타내는 숫자이므로 낮을수록 좋습니다)과 정확도입니다.\n",
        "results = model.evaluate(test_data,  test_labels, verbose=2)\n",
        "\n",
        "print(results)\n",
        "#accuracy: 0.8724(87.2%)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 - 1s - loss: 0.3278 - accuracy: 0.8724\n",
            "[0.3277806043624878, 0.8723999857902527]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXUItiEMQalb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#이 예제는 매우 단순한 방식을 사용하므로 87% 정도의 정확도를 달성했습니다. 고급 방법을 사용한 모델은 95%에 가까운 정확도를 얻습니다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdWEZDVBQfAe",
        "colab_type": "code",
        "outputId": "a6d8ba48-6c10-4dca-f94d-44a8aeadd0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#정확도와 손실 그래프 그리기\n",
        "#model.fit()은 History 객체를 반환합니다. 여기에는 훈련하는 동안 일어난 모든 정보가 담긴 딕셔너리(dictionary)가 들어 있습니다:\n",
        "#( 전체 코드를 다시 실행시키면 반복학습이 된다.(처음부터 다시하는게 아님) )\n",
        "history_dict = history.history # 앞쪽의 history가 우리가 만든 변수.내부에 있는 history변수\n",
        "history_dict.keys()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKHs8LbSQir3",
        "colab_type": "code",
        "outputId": "5da258a2-ca30-4106-e227-9cd7446abb32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "#네 개의 항목이 있습니다. 훈련과 검증 단계에서 모니터링하는 지표들입니다. \n",
        "#훈련 손실과 검증 손실을 그래프로 그려 보고, 훈련 정확도와 검증 정확도도 그래프로 그려서 비교해 보겠습니다:\n",
        "# 손실률을 나타내는 차트\n",
        "import matplotlib.pyplot as plt # 시각화 import \n",
        "\n",
        "acc = history_dict['accuracy'] # 훈련 정확도 값 꺼내고\n",
        "val_acc = history_dict['val_accuracy'] # 검증 정확도 값 꺼내고\n",
        "loss = history_dict['loss'] # 훈련 loss 값 꺼내고\n",
        "val_loss = history_dict['val_loss'] # 검증 loss 값 꺼내고\n",
        "\n",
        "epochs = range(1, len(acc) + 1) # 범위 만들 때 acc변수나 loss 변수나 데이터 개수가 똑같으니까 아무거나 써도 상관 없다. 40까지 나오게 하기 위해 +1 해준다.\n",
        "\n",
        "# \"bo\"는 \"파란색 점\"입니다\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b는 \"파란 실선\"입니다\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67Y4JPB-Toz4",
        "colab_type": "code",
        "outputId": "a17c4920-00ff-4f3f-f8af-be9f34ae63a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "# 정확도를 나타내는 차트\n",
        "plt.clf()   # 그림을 초기화합니다\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuYvTP3rTrGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "24d994f5-a9eb-485f-807d-429044ada028"
      },
      "source": [
        "# validation 사용자 관점\n",
        "# verification 개발자 관점\n",
        "'''\n",
        "이 그래프에서 점선은 훈련 손실과 훈련 정확도를 나타냅니다. \n",
        "실선은 검증 손실과 검증 정확도입니다.\n",
        "\n",
        "훈련 손실은 에포크마다 감소하고 훈련 정확도는 증가한다는 것을 주목하세요. \n",
        "경사 하강법 최적화를 사용할 때 볼 수 있는 현상입니다. 매 반복마다 최적화 대상의 값을 최소화합니다.\n",
        "\n",
        "하지만 검증 손실과 검증 정확도에서는 그렇지 못합니다. \n",
        "--------------- 약 20번째 에포크 이후가 최적점인 것 같습니다. -------------------\n",
        "이는 과대적합 때문입니다. 이전에 본 적 없는 데이터보다 훈련 데이터에서 더 잘 동작합니다. \n",
        "이 지점부터는 모델이 과도하게 최적화되어 테스트 데이터에서 일반화되기 어려운 훈련 데이터의 특정 표현을 학습합니다.\n",
        "\n",
        "여기에서는 과대적합을 막기 위해 단순히 20번째 에포크 근처에서 훈련을 멈출 수 있습니다. \n",
        "나중에 콜백(callback)을 사용하여 자동으로 이렇게 하는 방법을 배워 보겠습니다.\n",
        "'''"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n이 그래프에서 점선은 훈련 손실과 훈련 정확도를 나타냅니다. \\n실선은 검증 손실과 검증 정확도입니다.\\n\\n훈련 손실은 에포크마다 감소하고 훈련 정확도는 증가한다는 것을 주목하세요. \\n경사 하강법 최적화를 사용할 때 볼 수 있는 현상입니다. 매 반복마다 최적화 대상의 값을 최소화합니다.\\n\\n하지만 검증 손실과 검증 정확도에서는 그렇지 못합니다. 약 20번째 에포크 이후가 최적점인 것 같습니다. \\n이는 과대적합 때문입니다. 이전에 본 적 없는 데이터보다 훈련 데이터에서 더 잘 동작합니다. \\n이 지점부터는 모델이 과도하게 최적화되어 테스트 데이터에서 일반화되기 어려운 훈련 데이터의 특정 표현을 학습합니다.\\n\\n여기에서는 과대적합을 막기 위해 단순히 20번째 에포크 근처에서 훈련을 멈출 수 있습니다. \\n나중에 콜백(callback)을 사용하여 자동으로 이렇게 하는 방법을 배워 보겠습니다.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}