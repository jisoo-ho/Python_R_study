{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 평가\n",
    " - 정확도만으로 불균형한 레이블 데이터 세트에서 평가지표로 사용하기에는 부적합\n",
    " - 정확도가 가지는 분류 평가 지표로의 한계점을 극복하기 위해 여러 가지 분류 지표와 함께 적용해야 함\n",
    " \n",
    "### Confusion Matrix(혼동행렬, 오차행렬)\n",
    " - 이진 분류에서 성능 지표로 잘 활용되는 오차행렬(혼동행렬)은 학습된 분류 모델이 예측을 수행하면 얼마나 혼동될 수 있는지도 함께 보여주는 지표임\n",
    " - 이진 분류의 예측 오류가 얼마인지와 더불어 어떠한 유형의 예측오류가 발생하고 있는지를 함께 보여줌.\n",
    "\n",
    "### 평가 지표\n",
    "\n",
    "##### 모델에서 예측을 참 으로 했냐  거짓으로 했냐가 뒤에 붙은 N ,P\n",
    "##### 실제값이랑 비교했을때 실제랑 같으면 앞에 True, 다르면 False\n",
    " - TP, FP, FN, TP는 예측 클래스와 실제 클래스의 Positive 결정 값과 Negative 결정 값의 결합에 따라 결정\n",
    " - 앞문자 True/False는 예측값과 실제값이 같은가/틀린가를 의미하고 뒤 문자 Negative/Positive는 예측 결과 값이 부정/긍정을 의미\n",
    " - TN는 예측값을 Negative값 0으로 예측했고 실제값 역시 Negative 값0\n",
    " - FP는 예측값을 Positive 값 1로 예측했고 실제값은 Negative 값 0\n",
    " - FN은 예측값을 Negative 값 0으로 예측했고 실제값은 Positive 값 1\n",
    " - TP는 예측값을 Positive 값 1로 예측했고 실제값 역시 Positive 값 1\n",
    " - 정확도(accuracy) = (TP + TN) / (TP+TN+FP+FN)\n",
    " - 정밀도 = TP / (TP+FP) : P로 예측한 것 중에서 실제도 P\n",
    " - 재현율 = TP / (TP+FN) : 실제 P인 것 중에서 예측도 P\n",
    " - F1 = 2 * (정밀도 * 재현율) / (정밀도 + 재현율) : 정밀도와 재현율이 어느 한쪽으로 치우치지 않는 수치를 나타낼 때 높아짐\n",
    " - 정밀도와 재현율은 Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표\n",
    " - 재현율이 중요 지표인 경우는 실제 Positive 양성 데이터를 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우 (ex.보험사기)\n",
    " - 정밀도가 더 중요한 지표인 사례는 스팸 메일 여부를 판단하는 경우로 스팸 메일이 아닌데 스팸 메일로 분류해서 업무 차질 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.8015267175572519\n",
      "precision :  0.8170731707317073\n",
      "recall :  0.6442307692307693\n",
      "F1 :  0.7204301075268817\n"
     ]
    }
   ],
   "source": [
    "TN = 143\n",
    "FP = 15\n",
    "FN = 37\n",
    "TP = 67\n",
    "accuracy = ((TP+TN) / (TP+TN+FP+FN))\n",
    "precision = TP / (TP+FP)\n",
    "recall = TP / (TP+FN)\n",
    "F1 = 2 * (precision*recall) / (precision+recall)\n",
    "\n",
    "print('accuracy : ',accuracy)\n",
    "print('precision : ',precision)\n",
    "print('recall : ',recall)\n",
    "print('F1 : ',F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s 예측 정확도 : 0.8015267175572519\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "titanic_df=pd.read_csv('titanic3.csv')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "    df['cabin'].fillna('N', inplace=True)\n",
    "    df['fare'].fillna(df['fare'].mean(), inplace=True)\n",
    "    df['embarked'].fillna('N', inplace=True)\n",
    "    return df\n",
    "\n",
    "def drop_features(df):\n",
    "    df.drop(['home.dest','boat','body','name','ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def format_features(df):\n",
    "    df['cabin'] = df['cabin'].str[:1]\n",
    "    features = ['cabin','sex','embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        df[feature] = le.fit_transform(df[feature])\n",
    "    return df\n",
    "\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df\n",
    "\n",
    "t_df = transform_features(titanic_df)\n",
    "t_df.to_pickle('t_df.pkl')\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 독립변수, 종속변수 분리\n",
    "X = t_df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'cabin', 'embarked']]\n",
    "y = t_df['survived']\n",
    "\n",
    "# 독립변수 정규화(평균 0, 분산1인 표준정규분포)\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X) # StandardScaler : 표준정규분포\n",
    "\n",
    "# 학습용 데이터와 평가용 데이터를 8:2로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# SVM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "# 벡터 공간으로 매핑하는 함수를 커널이라고 함\n",
    "# kernal = 'rbf' 옵션으로 RBF(Radial Basis Function) 함수를 적용\n",
    "\n",
    "svm_model = svm.SVC(kernel='rbf', random_state=0) # random_state=0 으로 정해서 예측치 변동이 생기지 않게 한다.\n",
    "# kernel :  구분하는 선을 기준으로 선과 데이터의 거리가 margin이다. \n",
    "# 하지만, 하나의 선으로 분류할 수 있는 경우는 거의 없기 때문에 1차원을 2차원으로 만들고, 2차원을 3차원으로 만든다.\n",
    "# 선을 차원으로 바꿔주는 것이 kernel.\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "s_pred = svm_model.predict(X_test)\n",
    "\n",
    "s_accuracy = accuracy_score(y_test, s_pred)\n",
    "print('s 예측 정확도 :', s_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정밀도 및 재현율 활용시 유의사항\n",
    " - 정밀도와 재현율 성능 수치는 어느 한쪽만 참조하면 극단적인 수치 조작이 가능\n",
    " - 정밀도 100%가 되는 방법 : 확실한 기준이 되는 경우만 Positive로 예측하고 나머지는 모두 Negative로 예측 전체 환자 1000명 중 확실한 Positive징후만 가진 환자는 단1명 이라고 하면, 이 한명만 P로 예측하고 나머지는 모두 N으로 예측 FP는 0, TP는 1이 되며 정밀도 (TP/(TP+FP)는 1/(1+0)=1\n",
    " - 재현율이 100%가 되는 방법 : 모든 환자를 Positive로 예측 1000명의 환자 중 실제 양성인 사람이 30명 정도라도 TN이 수치에 포함되지 않고 FN은 0 이므로 재현율 (TP/(TP+FN)은 30/(30+0) =1\n",
    " - 분류가 정밀도, 재현율 중 하나에 상대적인 중요도를 부여할 수 있지만 하나만 강조해서는 안됨\n",
    " - 암 예측 모델에서 재현율을 높인다고 주로 양성만 판정한다면 환자의 부담과 불평이 커지게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143  15]\n",
      " [ 37  67]]\n",
      "0.8015267175572519 0.8170731707317073 0.6442307692307693 0.7204301075268817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       158\n",
      "           1       0.82      0.64      0.72       104\n",
      "\n",
      "    accuracy                           0.80       262\n",
      "   macro avg       0.81      0.77      0.78       262\n",
      "weighted avg       0.80      0.80      0.80       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def accuracy(TP,TN,FP,FN):\n",
    "    accuracy=((TP+TN) / (TP+TN+FP+FN))\n",
    "    return accuracy\n",
    "\n",
    "def precision(TP,FP):\n",
    "    precision=TP / (TP+FP)\n",
    "    return precision\n",
    "\n",
    "def recall(TP,FN):\n",
    "    recall = TP / (TP+FN)\n",
    "    return recall\n",
    "\n",
    "def F1(precision,recall):\n",
    "    F1=2* (precision*recall) / (precision+recall)\n",
    "    return F1\n",
    "\n",
    "# confusion matrix\n",
    "confusion = confusion_matrix(y_test, s_pred)\n",
    "print(confusion)\n",
    "#[[143  15]  생존자 기준일 때, 143이 TN, 15가 FP에 해당\n",
    "# [ 37  67]]  37이 FN에, 67이 TP에 해당\n",
    "\n",
    "#생존자 기준\n",
    "TP = 67\n",
    "TN = 143\n",
    "FP = 15\n",
    "FN = 37\n",
    "\n",
    "acc=accuracy(TP,TN,FP,FN) # 생존률과 사망률 둘다 비슷하다\n",
    "pre=precision(TP,FP) # 정밀도\n",
    "recall=recall(TP,FN) #재현율\n",
    "F1=F1(pre,recall)\n",
    "print(acc, pre, recall, F1)\n",
    "\n",
    "svm_report = classification_report(y_test, s_pred)\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8015267175572519 0.7944444444444444 0.9050632911392406 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "# 사망자 기준\n",
    "TN = 67\n",
    "TP = 143\n",
    "FN = 15\n",
    "FP = 37\n",
    "\n",
    "acc=accuracy(TP,TN,FP,FN)\n",
    "pre=precision(TP,FP)\n",
    "recall= TP / (TP+FN)\n",
    "F1= 2 * (pre*recall) / (pre+recall)\n",
    "print(acc, pre, recall, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[143  15]\n",
      " [ 37  67]]\n",
      "\n",
      "정확도 : 0.8015, 정밀도  0.8171, 재현율 : 0.6442, F1:0.7204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "def get_clf_eval(y_test, s_pred):\n",
    "    confusion = confusion_matrix(y_test, s_pred)\n",
    "    accuracy = accuracy_score(y_test, s_pred)\n",
    "    precision = precision_score(y_test, s_pred)\n",
    "    recall = recall_score(y_test, s_pred)\n",
    "    f1 = f1_score(y_test, s_pred)\n",
    "    \n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print()\n",
    "    print('정확도 : {0:.4f}, 정밀도  {1:.4f}, 재현율 : {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "\n",
    "get_clf_eval(y_test, s_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=11, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 1, 5, 10],\n",
       "                         'penalty': ['l2', 'l1']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 하이퍼 파라미터: {'C': 1, 'penalty': 'l2'}\n",
      "GridSearchCV 최고 정확도: 0.7841330599225337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=11, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[139  17]\n",
      " [ 30  76]]\n",
      "\n",
      "정확도 : 0.8206, 정밀도  0.8172, 재현율 : 0.7170, F1:0.7638\n",
      "Logistic Regression GSCV 예측 정확도 :  0.8206106870229007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "t_df = pd.read_pickle('t_df.pkl')\n",
    "\n",
    "y_df = t_df.survived\n",
    "X_df = t_df.drop('survived', axis=1)\n",
    "\n",
    "# 학습용 평가용 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=11)\n",
    "\n",
    "# 분류기 객체 생성\n",
    "lr_clf = LogisticRegression(random_state=11)\n",
    "# dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "# rf_clf = RandomForestClassifier(random_state=11)\n",
    "\n",
    "# GridSearchCV : 파라미터를 통해 성능을 튜닝. (타이타닉 생존률을 해결하기 위해 필요한 작업)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "parameters =  parameters = {'penalty':['l2','l1'],'C':[0.01,0.1,1,1,5,10]}\n",
    "\n",
    "grid_lrlf = GridSearchCV(lr_clf, param_grid=parameters, scoring='accuracy', cv=5, refit=True) \n",
    "\n",
    "display(grid_lrlf)\n",
    "grid_lrlf.fit(X_train, y_train) \n",
    "\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:', grid_lrlf.best_params_) \n",
    "\n",
    "print('GridSearchCV 최고 정확도:', grid_lrlf.best_score_) \n",
    "\n",
    "best_lrlf = grid_lrlf.best_estimator_\n",
    "display(best_lrlf)\n",
    "dpredictions = best_lrlf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, dpredictions)\n",
    "\n",
    "def get_clf_eval(y_test, dpredictions):\n",
    "    confusion = confusion_matrix(y_test, dpredictions)\n",
    "    accuracy = accuracy_score(y_test, dpredictions)\n",
    "    precision = precision_score(y_test, dpredictions)\n",
    "    recall = recall_score(y_test, dpredictions)\n",
    "    f1 = f1_score(y_test, dpredictions)\n",
    "    \n",
    "    print('오차행렬')\n",
    "    print(confusion)\n",
    "    print()\n",
    "    print('정확도 : {0:.4f}, 정밀도  {1:.4f}, 재현율 : {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))\n",
    "\n",
    "get_clf_eval(y_test, dpredictions)\n",
    "\n",
    "print('Logistic Regression GSCV 예측 정확도 : ', accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
